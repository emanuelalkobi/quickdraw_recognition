{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-07 16:46:17--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.20.133\n",
      "Connecting to raw.githubusercontent.com|151.101.20.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 760 [text/plain]\n",
      "Saving to: `mini_classes.txt'\n",
      "\n",
      "100%[======================================>] 760         --.-K/s   in 0s      \n",
      "\n",
      "2018-12-07 16:46:17 (171 MB/s) - `mini_classes.txt' saved [760/760]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"mini_classes.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "def download():\n",
    "    base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "    for c in classes:\n",
    "        cls_url = c.replace('_', '%20')\n",
    "        path = base+cls_url+'.npy'\n",
    "        print(path)\n",
    "        urllib.request.urlretrieve(path, 'data_all/'+c+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
     ]
    }
   ],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import *\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
    "    all_files = glob.glob(os.path.join(\"./data_all/\", '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load a subset of the data to memory \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "    \n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "\n",
    "    #separate into training and testing \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    \n",
    "#     print(x_train)\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, class_names = load_data()\n",
    "num_classes = len(class_names)\n",
    "image_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broom\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4e4e5d6f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(Xtrain))\n",
    "plt.imshow(Xtrain[idx].reshape(28,28)) \n",
    "print(class_names[int(Ytrain[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize\n",
    "x_train = Xtrain.reshape(Xtrain.shape[0], image_size, image_size).astype('float32')\n",
    "x_test = Xtest.reshape(Xtest.shape[0], image_size, image_size).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(Ytrain, num_classes)\n",
    "y_test = keras.utils.to_categorical(Ytest, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(Xtrain).reshape((-1, 28, 28))\n",
    "x_test = np.array(Xtest).reshape((-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 317,540\n",
      "Trainable params: 317,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "54s - loss: 2.5485 - acc: 0.3677 - val_loss: 2.0887 - val_acc: 0.4637\n",
      "Epoch 2/50\n",
      "53s - loss: 1.9340 - acc: 0.5022 - val_loss: 1.8516 - val_acc: 0.5214\n",
      "Epoch 3/50\n",
      "52s - loss: 1.7642 - acc: 0.5424 - val_loss: 1.7413 - val_acc: 0.5498\n",
      "Epoch 4/50\n",
      "53s - loss: 1.6574 - acc: 0.5682 - val_loss: 1.6584 - val_acc: 0.5698\n",
      "Epoch 5/50\n",
      "53s - loss: 1.5823 - acc: 0.5864 - val_loss: 1.6045 - val_acc: 0.5838\n",
      "Epoch 6/50\n",
      "53s - loss: 1.5243 - acc: 0.6007 - val_loss: 1.5626 - val_acc: 0.5941\n",
      "Epoch 7/50\n",
      "53s - loss: 1.4776 - acc: 0.6116 - val_loss: 1.5271 - val_acc: 0.6017\n",
      "Epoch 8/50\n",
      "53s - loss: 1.4461 - acc: 0.6187 - val_loss: 1.5166 - val_acc: 0.6055\n",
      "Epoch 9/50\n",
      "53s - loss: 1.4128 - acc: 0.6266 - val_loss: 1.4924 - val_acc: 0.6118\n",
      "Epoch 10/50\n",
      "53s - loss: 1.3890 - acc: 0.6328 - val_loss: 1.4735 - val_acc: 0.6173\n",
      "Epoch 11/50\n",
      "53s - loss: 1.3653 - acc: 0.6393 - val_loss: 1.4751 - val_acc: 0.6167\n",
      "Epoch 12/50\n",
      "53s - loss: 1.3445 - acc: 0.6429 - val_loss: 1.4550 - val_acc: 0.6205\n",
      "Epoch 13/50\n",
      "53s - loss: 1.3287 - acc: 0.6465 - val_loss: 1.4492 - val_acc: 0.6236\n",
      "Epoch 14/50\n",
      "53s - loss: 1.3067 - acc: 0.6524 - val_loss: 1.4414 - val_acc: 0.6271\n",
      "Epoch 15/50\n",
      "53s - loss: 1.2954 - acc: 0.6552 - val_loss: 1.4378 - val_acc: 0.6259\n",
      "Epoch 16/50\n",
      "53s - loss: 1.2791 - acc: 0.6587 - val_loss: 1.4337 - val_acc: 0.6282\n",
      "Epoch 17/50\n",
      "53s - loss: 1.2699 - acc: 0.6603 - val_loss: 1.4303 - val_acc: 0.6291\n",
      "Epoch 18/50\n",
      "53s - loss: 1.2546 - acc: 0.6646 - val_loss: 1.4260 - val_acc: 0.6304\n",
      "Epoch 19/50\n",
      "53s - loss: 1.2447 - acc: 0.6670 - val_loss: 1.4284 - val_acc: 0.6301\n",
      "Epoch 20/50\n",
      "53s - loss: 1.2366 - acc: 0.6686 - val_loss: 1.4276 - val_acc: 0.6316\n",
      "Epoch 21/50\n",
      "53s - loss: 1.2231 - acc: 0.6722 - val_loss: 1.4222 - val_acc: 0.6320\n",
      "Epoch 22/50\n",
      "53s - loss: 1.2142 - acc: 0.6734 - val_loss: 1.4168 - val_acc: 0.6336\n",
      "Epoch 23/50\n",
      "53s - loss: 1.2044 - acc: 0.6764 - val_loss: 1.4196 - val_acc: 0.6336\n",
      "Epoch 24/50\n",
      "53s - loss: 1.1933 - acc: 0.6790 - val_loss: 1.4206 - val_acc: 0.6341\n",
      "Epoch 25/50\n",
      "53s - loss: 1.1874 - acc: 0.6803 - val_loss: 1.4253 - val_acc: 0.6333\n",
      "Epoch 26/50\n",
      "54s - loss: 1.1799 - acc: 0.6822 - val_loss: 1.4255 - val_acc: 0.6318\n",
      "Epoch 27/50\n",
      "53s - loss: 1.1741 - acc: 0.6830 - val_loss: 1.4281 - val_acc: 0.6326\n",
      "Epoch 28/50\n",
      "53s - loss: 1.1675 - acc: 0.6848 - val_loss: 1.4261 - val_acc: 0.6323\n",
      "Epoch 29/50\n",
      "53s - loss: 1.1609 - acc: 0.6852 - val_loss: 1.4204 - val_acc: 0.6339\n",
      "Epoch 30/50\n",
      "53s - loss: 1.1574 - acc: 0.6859 - val_loss: 1.4249 - val_acc: 0.6341\n",
      "Epoch 31/50\n",
      "53s - loss: 1.1485 - acc: 0.6885 - val_loss: 1.4213 - val_acc: 0.6340\n",
      "Epoch 32/50\n",
      "53s - loss: 1.1405 - acc: 0.6902 - val_loss: 1.4262 - val_acc: 0.6348\n",
      "Epoch 33/50\n",
      "53s - loss: 1.1373 - acc: 0.6911 - val_loss: 1.4225 - val_acc: 0.6354\n",
      "Epoch 34/50\n",
      "54s - loss: 1.1326 - acc: 0.6921 - val_loss: 1.4249 - val_acc: 0.6353\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7b602b0b970b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=50,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.21%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
