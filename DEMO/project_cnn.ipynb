{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.dir_data='data/'\n",
    "        self.num_of_classes,self.dict =create_dic(self.dir_data)\n",
    "        self.image_size = 28\n",
    "        self.validate_data = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mini_classes.txt','w') as f:\n",
    "    for file in sorted(os.listdir('data/')):\n",
    "        if file.endswith(\".npy\"):\n",
    "            print(file.split(\".\")[0], file = f)\n",
    "f = open(\"mini_classes.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()\n",
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ambulance',\n",
       " 'apple',\n",
       " 'axe',\n",
       " 'basketball',\n",
       " 'bicycle',\n",
       " 'boomerang',\n",
       " 'butterfly',\n",
       " 'car',\n",
       " 'carrot',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'clock',\n",
       " 'cookie',\n",
       " 'cup',\n",
       " 'donut',\n",
       " 'envelope',\n",
       " 'flower',\n",
       " 'key',\n",
       " 'knife',\n",
       " 'lightning',\n",
       " 'pencil',\n",
       " 'pizza',\n",
       " 'rainbow',\n",
       " 'snake',\n",
       " 'spider',\n",
       " 'star',\n",
       " 'tractor',\n",
       " 'tree',\n",
       " 'whale',\n",
       " 'windmill']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(dir_data):\n",
    "    dict={}\n",
    "    i=0\n",
    "    for file in sorted(os.listdir(dir_data)):\n",
    "        if file.endswith(\".npy\"):\n",
    "            str=file.split(\".\")\n",
    "            dict[i]=str[0]\n",
    "            i=i+1\n",
    "    return i,dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(cnn):\n",
    "    dir_data='data/'\n",
    "    num_of_classess,dict=create_dic(dir_data)\n",
    "    data_l=np.zeros((1))\n",
    "    data_d=np.zeros((1,cnn.image_size*cnn.image_size))\n",
    "    index=0\n",
    "    class_names = []\n",
    "    for file in sorted(os.listdir(dir_data)):\n",
    "        if file.endswith(\".npy\"):\n",
    "            print(data_l.shape,data_d.shape,\"cur label num!\",index+1,file)\n",
    "            curr_data=np.load(dir_data+file)\n",
    "            data_size=curr_data.shape\n",
    "            #take only 30 percent of the data\n",
    "            part_data=int(0.3*(data_size[0]))\n",
    "            curr_data=curr_data[1:part_data,:]\n",
    "            \n",
    "\n",
    "            #change to white background\n",
    "            curr_data=255-curr_data;\n",
    "            data_d=np.concatenate((data_d,curr_data), axis=0)\n",
    "            data_l=np.concatenate((data_l,np.ones(curr_data.shape[0])*index))\n",
    "            index=index+1\n",
    "            class_names.append(file.split('.')[0])\n",
    "\n",
    "    data_l=np.expand_dims(data_l,1)\n",
    "    data_all=np.concatenate((data_d,data_l),axis=1)\n",
    "    data_all=np.random.permutation(data_all)\n",
    "\n",
    "    x_data=data_all[:,0:-1]\n",
    "    y_data=data_all[:,-1]\n",
    "    num_img=x_data.shape[0]\n",
    "    data_img=np.reshape(x_data,[num_img,cnn.image_size,cnn.image_size])\n",
    "\n",
    "\n",
    "    data_train=data_img[cnn.validate_data:,:,:]\n",
    "    data_train=np.expand_dims(data_train,3)\n",
    "\n",
    "    labels_train=y_data[cnn.validate_data:]\n",
    "    data_test=data_img[:cnn.validate_data:,:,:]\n",
    "    data_test=np.expand_dims(data_test,3)\n",
    "\n",
    "    labels_test=y_data[:cnn.validate_data]\n",
    "\n",
    "\n",
    "    return data_train,labels_train,data_test,labels_test,class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (1, 784) cur label num! 1 ambulance.npy\n",
      "(44401,) (44401, 784) cur label num! 2 apple.npy\n",
      "(87816,) (87816, 784) cur label num! 3 axe.npy\n",
      "(125051,) (125051, 784) cur label num! 4 basketball.npy\n",
      "(165187,) (165187, 784) cur label num! 5 bicycle.npy\n",
      "(203144,) (203144, 784) cur label num! 6 boomerang.npy\n",
      "(245947,) (245947, 784) cur label num! 7 butterfly.npy\n",
      "(281345,) (281345, 784) cur label num! 8 car.npy\n",
      "(336173,) (336173, 784) cur label num! 9 carrot.npy\n",
      "(375909,) (375909, 784) cur label num! 10 cat.npy\n",
      "(412868,) (412868, 784) cur label num! 11 chair.npy\n",
      "(479678,) (479678, 784) cur label num! 12 clock.npy\n",
      "(515837,) (515837, 784) cur label num! 13 cookie.npy\n",
      "(555241,) (555241, 784) cur label num! 14 cup.npy\n",
      "(594456,) (594456, 784) cur label num! 15 donut.npy\n",
      "(636680,) (636680, 784) cur label num! 16 envelope.npy\n",
      "(677137,) (677137, 784) cur label num! 17 flower.npy\n",
      "(720581,) (720581, 784) cur label num! 18 key.npy\n",
      "(768869,) (768869, 784) cur label num! 19 knife.npy\n",
      "(820664,) (820664, 784) cur label num! 20 lightning.npy\n",
      "(866131,) (866131, 784) cur label num! 21 pencil.npy\n",
      "(902730,) (902730, 784) cur label num! 22 pizza.npy\n",
      "(941840,) (941840, 784) cur label num! 23 rainbow.npy\n",
      "(979892,) (979892, 784) cur label num! 24 snake.npy\n",
      "(1016572,) (1016572, 784) cur label num! 25 spider.npy\n",
      "(1079405,) (1079405, 784) cur label num! 26 star.npy\n",
      "(1120689,) (1120689, 784) cur label num! 27 tractor.npy\n",
      "(1155691,) (1155691, 784) cur label num! 28 tree.npy\n",
      "(1199106,) (1199106, 784) cur label num! 29 whale.npy\n",
      "(1234055,) (1234055, 784) cur label num! 30 windmill.npy\n"
     ]
    }
   ],
   "source": [
    "quick_draw_cnn=cnn()\n",
    "x_train, y_train, x_test, y_test, class_names = load_data(quick_draw_cnn)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4d6b390518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], quick_draw_cnn.image_size, quick_draw_cnn.image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], quick_draw_cnn.image_size, quick_draw_cnn.image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               16500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                15030     \n",
      "=================================================================\n",
      "Total params: 109,258\n",
      "Trainable params: 109,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5], padding='same',input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=500, activation='relu'))\n",
    "model.add(layers.Dense(units=num_classes, activation='softmax')) \n",
    "# Train model\n",
    "adam = tf.train.AdamOptimizer()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1260247 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.3436 - top_k_categorical_accuracy: 0.9779 - val_loss: 0.3506 - val_top_k_categorical_accuracy: 0.9771\n",
      "Epoch 2/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.3225 - top_k_categorical_accuracy: 0.9792 - val_loss: 0.3391 - val_top_k_categorical_accuracy: 0.9792\n",
      "Epoch 3/10\n",
      "1260247/1260247 [==============================] - 43s 34us/step - loss: 0.3104 - top_k_categorical_accuracy: 0.9800 - val_loss: 0.3174 - val_top_k_categorical_accuracy: 0.9786\n",
      "Epoch 4/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.3013 - top_k_categorical_accuracy: 0.9806 - val_loss: 0.3287 - val_top_k_categorical_accuracy: 0.9780\n",
      "Epoch 5/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.2953 - top_k_categorical_accuracy: 0.9809 - val_loss: 0.3067 - val_top_k_categorical_accuracy: 0.9787\n",
      "Epoch 6/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.2910 - top_k_categorical_accuracy: 0.9812 - val_loss: 0.3242 - val_top_k_categorical_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.2874 - top_k_categorical_accuracy: 0.9813 - val_loss: 0.3210 - val_top_k_categorical_accuracy: 0.9782\n",
      "Epoch 8/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.2849 - top_k_categorical_accuracy: 0.9815 - val_loss: 0.3225 - val_top_k_categorical_accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "1260247/1260247 [==============================] - 42s 34us/step - loss: 0.2820 - top_k_categorical_accuracy: 0.9817 - val_loss: 0.3135 - val_top_k_categorical_accuracy: 0.9782\n",
      "Epoch 10/10\n",
      "1260247/1260247 [==============================] - 43s 34us/step - loss: 0.2794 - top_k_categorical_accuracy: 0.9818 - val_loss: 0.3085 - val_top_k_categorical_accuracy: 0.9792\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Test accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_data=(x_test, y_test), batch_size=quick_draw_cnn.batch_size, epochs=10)\n",
    "acc = model.evaluate(x_test, y_test,batch_size=quick_draw_cnn.batch_size)\n",
    "print('Test accuracy:', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lightning', 'axe', 'boomerang', 'star', 'rainbow']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4e689a42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze()) \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handler:\n",
    "    for item in class_names:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "model.save('keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 18.0\n",
      "    Uninstalling pip-18.0:\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/share/pkg/python/3.6.2/install/bin/pip'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\r\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras keras.h5 model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
